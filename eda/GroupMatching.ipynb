{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da7cb22-d797-45a0-b2ae-884fbd9e55b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "classification1 = pd.read_excel('../data/train_Ametist/classification.xlsx', sheet_name='Материалы, изд, констр и оборуд')\n",
    "classification2 = pd.read_excel('../data/train_Ametist/classification.xlsx', sheet_name='Машины и механизмы')\n",
    "classification = pd.concat([classification1, classification2], axis=0).dropna()\n",
    "train_data = pd.read_excel('../data/train_Ametist/train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a85b863-c5df-41fb-a662-bac8e802ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_group(text):\n",
    "    text = str(text)\n",
    "    if 'Группа' in text:\n",
    "        return text.split(':')[-1].replace('Группа ', '').strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "classification_groups = classification.copy()\n",
    "classification_groups['group'] = classification_groups['Классификатор строительных ресурсов'].apply(extract_group)\n",
    "classification_groups['group'] = classification_groups['group'].fillna(method='ffill')\n",
    "classification_groups = classification_groups.dropna()\n",
    "classification_groups = classification_groups.loc[classification_groups.group.apply(len) > 0]\n",
    "classification_groups = classification_groups.loc[classification_groups['Классификатор строительных ресурсов'].apply(lambda x: all([c in '0123456789.-' for c in x]))]\n",
    "classification_groups = classification_groups.drop_duplicates(subset='group', keep='last')\n",
    "classification_groups = classification_groups.drop(columns=['Unnamed: 1', 'Unnamed: 2']).rename(columns={'Классификатор строительных ресурсов': 'code'}).reset_index(drop=True)\n",
    "classification_groups['code'] = classification_groups['code'].apply(lambda x: '.'.join(x.split('-')[0].split('.')[4:]))\n",
    "train_data['group_code'] = train_data['ref_code'].apply(lambda x: '.'.join(x.split('-')[0].split('.')[4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "446845a8-310a-45a9-9af5-8abb69a4d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.764219760894775\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm')  # нужно скачать: python -m spacy download ru_core_news_sm\n",
    "\n",
    "\n",
    "def strip_features_and_normaize(text):\n",
    "    text = re.sub(r'\\s*-\\s*', '/', text)\n",
    "    text = re.sub(r'\\(.*?\\)|\\[.*?\\]|\\{.*?\\}', '', text)\n",
    "    result = nlp(text)\n",
    "    filtered_result = filter(lambda x: x.pos_ in ['NOUN', 'ADJ', 'VERB', 'PROPN'] and \n",
    "                             x.dep_ in ['ROOT', 'amod', 'nsubj', \n",
    "                                        'advmod', 'nmod', 'nsubjpass', \n",
    "                                        'nmod:npmod', 'nmod:poss',\n",
    "                                        'nmod:tmod', 'obl'] and\n",
    "                             len(x.text) > 2, result)\n",
    "\n",
    "    return ' '.join(list([e.lemma_.strip() for e in filtered_result]))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "train_data['record_name_strip'] = train_data.record_name.apply(strip_features_and_normaize)\n",
    "train_data['record_name_strip_2'] = train_data.record_name_2.apply(strip_features_and_normaize)\n",
    "classification_groups['group_strip'] = classification_groups.group.apply(strip_features_and_normaize)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545f6c8a-621b-4e96-9813-a95018415b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/anaconda3/envs/ametist/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/peter/anaconda3/envs/ametist/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('DiTy/bi-encoder-russian-msmarco')\n",
    "group_embeddings = model.encode(classification_groups.group_strip.to_list(), convert_to_tensor=True)\n",
    "wrong_embeddings1 = model.encode(train_data.record_name_strip.to_list(), convert_to_tensor=True)\n",
    "wrong_embeddings2 = model.encode(train_data.record_name_strip_2.to_list(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cdc0e30-71a0-47dd-bd76-57f70d89964c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2128"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_codes = set(classification_groups.code.to_list())\n",
    "\n",
    "num_equal_codes = sum([c in group_codes for c in train_data.group_code])\n",
    "num_equal_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6835f-439a-4ce4-b172-f6391ea62326",
   "metadata": {},
   "source": [
    "## One-level  matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c3daf2e7-8667-4842-ab24-705c6feaba53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eda6d17570e4c8dbbf95970ee927738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.12077067669172932"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import trange\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "correct_matches = 0\n",
    "\n",
    "\n",
    "def check_matching(match_from_code, match_to_codes, emb_distances, depth=-1):\n",
    "    if depth > 0:\n",
    "        return ''.join(match_from_code.split('.')[:depth]) == ''.join(match_to_codes[torch.argmax(emb_distances).cpu().item()].split('.')[:depth])\n",
    "    return match_from_code == match_to_codes[torch.argmax(emb_distances).cpu().item()]\n",
    "\n",
    "\n",
    "for i in trange(wrong_embeddings1.shape[0]):\n",
    "    group_emb_distances = torch.abs(util.cos_sim(group_embeddings, wrong_embeddings1[i].unsqueeze(0)))\n",
    "\n",
    "    if check_matching(train_data.group_code.iloc[i], classification_groups.code, group_emb_distances, depth=-1):\n",
    "        correct_matches += 1\n",
    "correct_matches / num_equal_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3864cc3f-1605-4c00-9350-25ae864faecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1584f1fcd0a4c36ac15de1fc8e37d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.11701127819548872"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_matches = 0\n",
    "\n",
    "for i in trange(wrong_embeddings2.shape[0]):\n",
    "    group_emb_distances = torch.abs(util.cos_sim(group_embeddings, wrong_embeddings2[i].unsqueeze(0)))\n",
    "\n",
    "    if check_matching(train_data.group_code.iloc[i], classification_groups.code, group_emb_distances, depth=-1):\n",
    "        correct_matches += 1\n",
    "correct_matches / num_equal_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40fcdc3-6e19-437e-bf88-90fe87ce7bce",
   "metadata": {},
   "source": [
    "## Hierarchial matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a776810b-bf79-437b-9331-a49fe70ee2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>measure</th>\n",
       "      <th>level0_code</th>\n",
       "      <th>level1_code</th>\n",
       "      <th>level2_code</th>\n",
       "      <th>level3_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01.1.01.01-0002</td>\n",
       "      <td>Детали фасонные коньковые к листам хризотилцем...</td>\n",
       "      <td>100 компл</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01.1.01.02-0011</td>\n",
       "      <td>Доска электротехническая дугостойкая (АЦЭИД), ...</td>\n",
       "      <td>т</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>01.1.01.04-1018</td>\n",
       "      <td>Листы хризотилцементные волнистые, профиль 40/...</td>\n",
       "      <td>м2</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>01.1.01.04-1022</td>\n",
       "      <td>Листы хризотилцементные волнистые, профиль 40/...</td>\n",
       "      <td>м2</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01.1.01.04-1024</td>\n",
       "      <td>Листы хризотилцементные волнистые, профиль 40/...</td>\n",
       "      <td>м2</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01.1.01.04-1032</td>\n",
       "      <td>Листы хризотилцементные волнистые, профиль 40/...</td>\n",
       "      <td>м2</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01.1.01.04-1038</td>\n",
       "      <td>Листы хризотилцементные волнистые, профиль 51/...</td>\n",
       "      <td>м2</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>01.1.01.04-1046</td>\n",
       "      <td>Листы хризотилцементные волнистые, профиль 51/...</td>\n",
       "      <td>м2</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>01.1.01.04-1068</td>\n",
       "      <td>Листы хризотилцементные волнистые, профиль 40/...</td>\n",
       "      <td>м2</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>01.1.01.05-0011</td>\n",
       "      <td>Листы хризотилцементные плоские непрессованные...</td>\n",
       "      <td>м2</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               code                                               name  \\\n",
       "5   01.1.01.01-0002  Детали фасонные коньковые к листам хризотилцем...   \n",
       "8   01.1.01.02-0011  Доска электротехническая дугостойкая (АЦЭИД), ...   \n",
       "11  01.1.01.04-1018  Листы хризотилцементные волнистые, профиль 40/...   \n",
       "13  01.1.01.04-1022  Листы хризотилцементные волнистые, профиль 40/...   \n",
       "15  01.1.01.04-1024  Листы хризотилцементные волнистые, профиль 40/...   \n",
       "17  01.1.01.04-1032  Листы хризотилцементные волнистые, профиль 40/...   \n",
       "19  01.1.01.04-1038  Листы хризотилцементные волнистые, профиль 51/...   \n",
       "23  01.1.01.04-1046  Листы хризотилцементные волнистые, профиль 51/...   \n",
       "27  01.1.01.04-1068  Листы хризотилцементные волнистые, профиль 40/...   \n",
       "30  01.1.01.05-0011  Листы хризотилцементные плоские непрессованные...   \n",
       "\n",
       "      measure level0_code level1_code level2_code level3_code  \n",
       "5   100 компл          01           1          01          01  \n",
       "8           т          01           1          01          02  \n",
       "11         м2          01           1          01          04  \n",
       "13         м2          01           1          01          04  \n",
       "15         м2          01           1          01          04  \n",
       "17         м2          01           1          01          04  \n",
       "19         м2          01           1          01          04  \n",
       "23         м2          01           1          01          04  \n",
       "27         м2          01           1          01          04  \n",
       "30         м2          01           1          01          05  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchial_classification = classification.copy()\n",
    "hierarchial_classification = hierarchial_classification.rename(columns={'Классификатор строительных ресурсов': 'code', 'Unnamed: 1': 'name', 'Unnamed: 2': 'measure'})\n",
    "hierarchial_classification = hierarchial_classification.loc[hierarchial_classification.code.apply(lambda x: all(c in '0123456789-.' for c in x))]\n",
    "hierarchial_classification = hierarchial_classification.loc[hierarchial_classification.code.apply(lambda x: len(x.split('.')) < 5)]\n",
    "hierarchial_classification = hierarchial_classification.drop_duplicates(subset='name', keep='first')\n",
    "hierarchial_classification['level0_code'] = hierarchial_classification.code.apply(lambda x: x.split('.')[0])\n",
    "hierarchial_classification['level1_code'] = hierarchial_classification.code.apply(lambda x: x.split('.')[1])\n",
    "hierarchial_classification['level2_code'] = hierarchial_classification.code.apply(lambda x: x.split('.')[2])\n",
    "hierarchial_classification['level3_code'] = hierarchial_classification.code.loc[hierarchial_classification.code.apply(lambda x: len(x.split('.')) > 3)].apply(lambda x: x.split('.')[3])\n",
    "hierarchial_classification['level3_code'] = hierarchial_classification.level3_code.fillna('01-0')\n",
    "hierarchial_classification['level3_code'] = hierarchial_classification.level3_code.apply(lambda x: x.split('-')[0])\n",
    "hierarchial_classification['level2_code'] = hierarchial_classification.level2_code.apply(lambda x: x.split('-')[0])\n",
    "print(hierarchial_classification.shape[0])\n",
    "hierarchial_classification.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "783ed8d4-1947-4674-b0eb-28070790f023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 1.55 s, total: 1min 9s\n",
      "Wall time: 55.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "level0_embs = hierarchial_classification.groupby(f'level0_code').name.apply(lambda x: model.encode(x.to_list(), convert_to_tensor=True).mean(dim=0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fa80dd-473e-4cb5-8aba-95a4a366ef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "# levelwise embeddings лучше посчитать заранее!\n",
    "\n",
    "\n",
    "def predict_hierachically(match_from_name, hierarchial_classification):\n",
    "    match_from_emb = model.encode(match_from_name, convert_to_tensor=True)\n",
    "    best_group = list()\n",
    "    levelwise_groupby = hierarchial_classification.copy()\n",
    "\n",
    "    for hierarchy_level in range(4):\n",
    "        if levelwise_groupby[f'level{hierarchy_level}_code'].isna().any():\n",
    "            break\n",
    "\n",
    "        levelwise_groupby = levelwise_groupby.groupby(f'level{hierarchy_level}_code')\n",
    "        if hierarchy_level == 0:\n",
    "            level_embs = level0_embs\n",
    "        else:\n",
    "            level_embs = levelwise_groupby.name.apply(lambda x: model.encode(x.to_list(), convert_to_tensor=True).mean(dim=0).cpu())\n",
    "        level_embs = torch.stack(level_embs.to_list()).to('cuda:0')\n",
    "\n",
    "        emb_distances = torch.abs(F.cosine_similarity(level_embs, match_from_emb.unsqueeze(0), dim=1))\n",
    "\n",
    "        best_group_on_level = list(levelwise_groupby.groups.keys())[torch.argmax(emb_distances).cpu().item()]\n",
    "\n",
    "        best_group.append(best_group_on_level)\n",
    "        levelwise_groupby = levelwise_groupby.get_group(best_group_on_level)\n",
    "\n",
    "    return '.'.join(best_group)\n",
    "\n",
    "pred_groups = list()\n",
    "for idx in trange(train_data.shape[0]):\n",
    "    pred_groups.append(predict_hierachically(train_data.record_name_strip.iloc[idx], hierarchial_classification))\n",
    "\n",
    "for i in range(3):\n",
    "    level_group_code_gt = train_data.group_code.apply(lambda x: '.'.join(x.split('.')[:i+1]))\n",
    "    level_group_code_pred = list(map(lambda x: '.'.join(x.split('.')[:i+1], pred_groups)))\n",
    "\n",
    "    print(sum(level_group_code_gt == level_group_code_pred) / len(level_group_code_pred))\n",
    "    \n",
    "# match_from_name = train_data.record_name_strip.iloc[idx]\n",
    "# match_from_emb = model.encode(match_from_name, convert_to_tensor=True)\n",
    "# best_group = list()\n",
    "# levelwise_groupby = hierarchial_classification.copy()\n",
    "\n",
    "# print('taget:', match_from_name)\n",
    "# print('target_group:', train_data.group_code.iloc[idx])\n",
    "\n",
    "# for hierarchy_level in range(4):\n",
    "#     if levelwise_groupby[f'level{hierarchy_level}_code'].isna().any():\n",
    "#         break\n",
    "\n",
    "#     levelwise_groupby = levelwise_groupby.groupby(f'level{hierarchy_level}_code')\n",
    "#     if hierarchy_level == 0:\n",
    "#         level_embs = level0_embs\n",
    "#     else:\n",
    "#         level_embs = levelwise_groupby.name.apply(lambda x: model.encode(x.to_list(), convert_to_tensor=True).mean(dim=0).cpu())\n",
    "#     level_embs = torch.stack(level_embs.to_list()).to('cuda:0')\n",
    "\n",
    "#     emb_distances = torch.abs(F.cosine_similarity(level_embs, match_from_emb.unsqueeze(0), dim=1))\n",
    "\n",
    "#     best_group_on_level = list(levelwise_groupby.groups.keys())[torch.argmax(emb_distances).cpu().item()]\n",
    "\n",
    "#     best_group.append(best_group_on_level)\n",
    "#     levelwise_groupby = levelwise_groupby.get_group(best_group_on_level)\n",
    "\n",
    "# print('predicted_group:', '.'.join(best_group))\n",
    "# hierarchial_classification.loc[hierarchial_classification.code.apply(lambda x: x.startswith('.'.join(best_group)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c073963e-8377-4029-8ce2-7473d1e1403a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ametist",
   "language": "python",
   "name": "ametist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
